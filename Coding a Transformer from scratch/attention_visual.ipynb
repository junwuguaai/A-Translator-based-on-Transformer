{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-03T13:32:57.864656Z",
     "start_time": "2024-12-03T13:32:57.832069Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import Transformer\n",
    "from config import get_config,get_weights_file_path\n",
    "from train import get_model,get_ds,greedy_decode\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'altair'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mconfig\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_config,get_weights_file_path\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtrain\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_model,get_ds,greedy_decode\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01maltair\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01malt\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'altair'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T13:33:04.233598Z",
     "start_time": "2024-12-03T13:33:04.224803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Define the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')"
   ],
   "id": "fcf75de793620ca3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "config = get_config()\n",
    "train_dataloader, val_dataloader,vocab_src,vocab_tgt = get_ds(config)\n",
    "model = get_model(config,vocab_src.get_vocab_size(),vocab_tgt.get_vocab_size()).to(device)\n",
    "\n",
    "#Load the pretrained weights\n",
    "model_filename = get_weights_file_path(config,f\"49\")\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])"
   ],
   "id": "282ee446b948c20a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_next_batch():\n",
    "    batch = next(iter(val_dataloader))\n",
    "    encoder_input = batch['encoder_input'].to(device)\n",
    "    encoder_mask = batch['encoder_mask'].to(device)\n",
    "    decoder_input = batch['decoder_input'].to(device)\n",
    "    decoder_mask = batch['decoder_mask'].to(device)\n",
    "    \n",
    "    encoder_input_tokens = [vocab_src.id_to_token(idx) for idx in encoder_input[0].cpu().numpy()]\n",
    "    decoder_input_tokens = [vocab_tgt.id_to_token(idx) for idx in decoder_input[0].cpu().numpy()]\n",
    "    \n",
    "    model_out = greedy_decode(model,encoder_input,encoder_mask,vocab_src,vocab_tgt,config['seq_len'],device)\n",
    "    \n",
    "    return batch,encoder_input_tokens,decoder_input_tokens"
   ],
   "id": "10b884dddffa460b"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def mtx2df(m,max_row,max_col,row_tokens,col_tokens):\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            (\n",
    "                r,\n",
    "                c,\n",
    "                float(m[r,c]),\n",
    "                \"%.3d %s\" % (r,row_tokens[r] if len(row_tokens)>r else \"<blank>\"),\n",
    "                \"%.3d %s\" % (c,row_tokens[c] if len(col_tokens)>c else \"<blank>\"),\n",
    "            )\n",
    "            for r in range(m.shape[0])\n",
    "            for c in range(m.shape[1])\n",
    "            if r < max_row and c < max_col\n",
    "        ],\n",
    "        columns=[\"row\",\"column\",\"value\",\"row_token\",\"col_token\"],\n",
    "    )\n",
    "def get_attn_map(attn_type:str,layer:int,head:int):\n",
    "    if attn_type == 'encoder':\n",
    "        attn = model.encoder.layers[layer].self_attention_block.attention_scores\n",
    "    elif attn_type == 'decoder':\n",
    "        attn = model.decoder.layers[layer].self_attention_block.attention_scores\n",
    "    elif attn_type == 'encoder-decoder':\n",
    "        attn = model.decoder.layers[layer].cross_attention_block.attention_scores\n",
    "    return attn[0,head].data\n",
    "\n",
    "def attn_map(attn_type,layer,head,row_tokens,col_tokens,max_sentence_len):\n",
    "    df = mtx2df(\n",
    "        get_attn_map(attn_type,layer,head),\n",
    "        max_sentence_len,\n",
    "        max_sentence_len,\n",
    "        row_tokens,\n",
    "        col_tokens,\n",
    "    )\n",
    "    return (\n",
    "        alt.Chart(data=df)\n",
    "        .mark_rect()\n",
    "        .encode(\n",
    "            x=alt.X(\"col_token\",axis=alt.Axis(title=\"\")),\n",
    "            y=alt.Y(\"row_token\",axis=alt.Axis(title=\"\")),\n",
    "            color=\"value\",\n",
    "            tooltip=[\"row\",\"column\",\"value\",\"row_token\",\"col_token\"],\n",
    "        )\n",
    "        .properties(height=400,width=400,title=f\"Layer {layer} Head {head}\")\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "def get_all_attention_maps(attn_type:str,layers:list[int],heads:list[int],row_tokens:list,col_tokens,max_sentence_len:int):\n",
    "    charts = []\n",
    "    for layer in layers:\n",
    "        rowCharts = []\n",
    "        for head in heads:\n",
    "            rowCharts.append(attn_map(attn_type,layer,head,row_tokens,col_tokens,max_sentence_len))\n",
    "        charts.append(alt.hconcat(*rowCharts))\n",
    "    return alt.vconcat(*charts)"
   ],
   "id": "ce412869149bdfbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch,encoder_input_tokens,decoder_input_tokens = load_next_batch()\n",
    "print(f'Source:{batch[\"src_text\"][0]}')\n",
    "print(f'Target:{batch[\"tgt_text\"][0]}')\n",
    "sentence_len = encoder_input_tokens.index('[PAD]')"
   ],
   "id": "c502aba35f68ec1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "layers = [0,1,2]\n",
    "heads = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "#Encoder Self_Attention\n",
    "get_all_attention_maps(\"encoder\",layers,heads,encoder_input_tokens,encoder_input_tokens,min(20,sentence_len))"
   ],
   "id": "6b54f26cc59f22f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Decoder Self_Attention\n",
    "get_all_attention_maps(\"decoder\",layers,heads,decoder_input_tokens,decoder_input_tokens,min(20,sentence_len))"
   ],
   "id": "9bc612c8eaa1c8a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Cross Attention\n",
    "\n",
    "get_all_attention_maps(\"encoder-decoder\",layers,heads,encoder_input_tokens,decoder_input_tokens,min(20,sentence_len))"
   ],
   "id": "b3e7cd17e2b27bea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
